---
layout: post
bigtitle:  "03. RandomForest"
subtitle:   "앙상블"
categories:
    - study
    - programs
tags:
  - Machine Leraning
related_posts:
  - _posts/study/programs/2022-08-01-01.-Machine-Learning.md
  - _posts/study/programs/2022-08-02-02.-Ensemble.md
comments: true
published: true
---

* toc
{:toc}

<center><img src="../../../assets/img/study/randomforest(1).png" width="100%" height="100%"></center>  

# Random Forest  

## 1. 정의  
> 랜덤포레스트 알고리즘은 여러 개의 단순 Tree들을 조합하여 하나의 결과를 도출하는  가장 흔히 알려진 머신러닝 알고리즘 중 하나이다.  


## 2. 작동원리  
<p>
  <div class=pull-right>
    <center><img src="../../../assets/img/study/randomforest(2).png" width="50%" height="50%"></center>  
  </div>
    랜덤포레스트 알고리즘은 bagging을 이용한 앙상블 기법 중 하나이다. 여러 Tree들을 앙상블할 때, 모두 같은 구조를 가지는 Tree들이면 앙상블에 의미가 없어진다. 이를 위하여 RandomFroest에서는 부트스트랩 샘플링과 feature randomness을 이용하여 나무를 만든다.  
</p>

### 1) 부트스트랩  
부트스트랩 샘플링이란 n개의 원래의 훈련 데이터셋에서 중복을 허용하며 랜덤으로 n개를 추출하는 것을 뜻한다.

## 3. 장ㆍ단점  
> **장점**  
  - 예측의 변동성이 줄어든다.  
    기존 훈련 데이터셋에서 랜덤으로 추출하므로 한쪽으로 기울어진 결과가 나오지 않는다.  
  - 과적합을 방지한다.  
    부트스트랩셋을 만들 때, 일부 데이터는 뽑히지 않는 경우가 발생하여 과적합을 방지한다.  
  - 결측치의 비율이 높아져도 높은 정확도를 나타낸다.  
  - 변수의 중요성을 파악할 수 있다.  
    나무 모형에서 나누어지는 기준을 보고 변수의 중요성을 파악할 수 있다.

> **단점**  
  - 메모리 사용량이 굉장히 많다.  
    Decision Tree를 만드는 것 자체가 메모리를 많이 사용하는데, 여러 개를 종합 해야하니 메모리 사용량이 크다.  
  - 예측과 크게 상관없는 변수가 늘어나면 성능이 떨어진다.  
    모형 내에서 따로 변수선택의 과정을 거치지 않기 때문에 예측과 크게 상관없는 
    변수가 들어온다면 정확도가 떨어진다. 하나의 나무를 만들 때 사용되는 변수 수를 
    늘려 이 문제를 해결할 수 있지만, 그러면 계산 속도가 느려진다.  
